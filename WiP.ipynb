{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phases 1 and 2 Revisited**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Prompt*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Microsoft's Making Moves into Movies**\n",
    "\n",
    ">* What types of movies are performing the best a the box offices?\n",
    ">* What actions should they take based on the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Questions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**What questions will guide my process?**\n",
    "\n",
    ">* **Q1:What genres show the best performance?**\n",
    "    * What is the best way to evaluate the *profitability* of the movies?\n",
    "        * Gross\n",
    "        * Profit\n",
    "        * ROI\n",
    "    * What is the best way to determine the best *quality* of each movie?\n",
    ">\n",
    ">\n",
    ">* **Q2:How do we determine the \"best\" features?**\n",
    "    * Which features would have the greatest impact on each of the performance metrics?\n",
    "    * How to optimize for all three metrics?\n",
    ">\n",
    ">\n",
    ">* **Q3:What release times are best for gross value?**\n",
    "    * Seasons vs. Quarters?\n",
    "        * *Would it make more sense either way? Could there be a benefit for inferences/predictions via LinReg modeling?*\n",
    ">\n",
    ">\n",
    ">* **Q4:Which directors show the strongest/weakest performance?**\n",
    "    * Get director names, ID\n",
    "    * Add names to dataframe including the movie ID and gross performance/highest reviews\n",
    ">\n",
    ">\n",
    ">* **Q5:What features would give the strongest indications of performance?**\n",
    ">\n",
    ">\n",
    ">* **Q6:How can we determine whether or not a movie is \"successful\" or not?**\n",
    "\n",
    "---\n",
    "\n",
    "**Goals:**\n",
    ">\n",
    ">* **Determine KPIs**\n",
    "    * How to measure a movie's success?\n",
    ">\n",
    ">\n",
    ">* **Use linear regression modeling to determine the top 5 features for each target.**\n",
    "    * To what degree do the features overlap?\n",
    "    * What would be the top 3-5 features on which to focus to create the \"best\" movie (balancing all of the metrics)?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‡ **WIP Current Status** ðŸŽ‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Update this section after each coding session - quick review/AAG overview of what is done and what is do-do*\n",
    ">\n",
    ">*Imagine its a scrum/kanban board in the notebook*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Done**\n",
    "\n",
    ">* **Data Cleaning:** pulled, df'ed, coverted datatypes, filled \"N/A\" values\n",
    ">\n",
    ">\n",
    ">* **FE:** \n",
    ">   * Months, Seasons, Quarters\n",
    ">   * Genres to list, then to individual rows\n",
    ">   * Profit and ROI metrics\n",
    ">\n",
    ">\n",
    ">* **Visualizations:**\n",
    ">   * Seasonal performance - gross, profit, ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ¨**To-Do**âœ¨\n",
    "\n",
    ">* Explore full concat/merge of dataframes?\n",
    ">\n",
    ">* MultiCollinearity and Correlations\n",
    ">   * âœ¨ Which features to compare against each other?\n",
    ">   * âœ¨ How to create the matrix with these features?\n",
    ">\n",
    ">\n",
    ">* Statistical Testing\n",
    ">\n",
    ">\n",
    ">* LinReg\n",
    ">\n",
    ">\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Process*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. Import .csv's\n",
    ">2. Clean data\n",
    ">3. EDA w. visuals\n",
    ">4. **Determine initial insights and actions**\n",
    ">5. Create new features\n",
    ">6. Test for correlations/multicollinearity\n",
    ">7. Perform statistical testing\n",
    ">8. Create LinReg model for **inference**\n",
    ">9. Create LinReg model for **predictions**\n",
    ">10. **Present final results for inferences, predictions**\n",
    "    1. Include initial, final insights and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:02:25.898751Z",
     "start_time": "2021-06-24T21:02:22.218691Z"
    }
   },
   "outputs": [],
   "source": [
    "## Accessing stored data\n",
    "import csv\n",
    "import os,glob\n",
    "\n",
    "## Data exploration and statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Creating Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modeling - Statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sms\n",
    "\n",
    "# Modeling - SKLearn\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "## Settings\n",
    "%matplotlib inline\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "sns.set_context('notebook', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:02:25.914747Z",
     "start_time": "2021-06-24T21:02:25.900747Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Creating list of files to loop through for data\n",
    "data_folder = 'zippedData/'\n",
    "data_files = glob.glob(f'{data_folder}*.csv*')\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:02:29.895829Z",
     "start_time": "2021-06-24T21:02:25.917747Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Looping through individual data files\n",
    "\n",
    "## Code adapted from James Irving\n",
    "## Source: youtube.com/watch?v=rufvTgBEYN8&list=PLFknVelSJiSxSwXifV_ysDg50fzbuTzVt&index=41\n",
    "\n",
    "clean_file_names = {}\n",
    "split = '-----'*25\n",
    "\n",
    "for file in data_files:\n",
    "    name = file.replace('.csv.gz','').split('\\\\')[-1].replace('.','_')\n",
    "    print(split)\n",
    "    \n",
    "    print(f\"Preview of {name}:\")\n",
    "    clean_file_names[name] = pd.read_csv(file)\n",
    "    display(clean_file_names[name].head(5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Files Dictionary and dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I am curious if I can create a single dataframe from all of the data.\n",
    ">\n",
    "> There are many repeated column names and the data seems to be similar. Is it possible/feasible/cost-effective to merge them all together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:05:29.506953Z",
     "start_time": "2021-06-24T21:05:29.493926Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting the dataframes contained in the dictonary of clean file names\n",
    "\n",
    "list_keys = list(clean_file_names.keys())\n",
    "list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:06:25.976655Z",
     "start_time": "2021-06-24T21:06:25.910659Z"
    }
   },
   "outputs": [],
   "source": [
    "## Exploring the dictionary values\n",
    "\n",
    "clean_file_names.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:08:10.791961Z",
     "start_time": "2021-06-24T21:08:10.734961Z"
    }
   },
   "outputs": [],
   "source": [
    "## Converting from dict.values dt to list\n",
    "\n",
    "list_dfs = list(clean_file_names.values())\n",
    "list_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:08:11.119869Z",
     "start_time": "2021-06-24T21:08:11.104877Z"
    }
   },
   "outputs": [],
   "source": [
    "## Calculating the number of dataframes stored in this list\n",
    "\n",
    "len(list_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:07:37.422018Z",
     "start_time": "2021-06-24T21:07:37.402030Z"
    }
   },
   "outputs": [],
   "source": [
    "## Exploring the individual list items - discovering the dataframes\n",
    "\n",
    "list(clean_file_names.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:21:57.237073Z",
     "start_time": "2021-06-24T21:21:57.216053Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting the column index\n",
    "\n",
    "list_dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœ¨ Concat/merge/join?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rabbit hole: combining all into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:29:01.999656Z",
     "start_time": "2021-06-24T21:29:01.984659Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Getting unique column indices\n",
    "\n",
    "# unique_col = []\n",
    "\n",
    "# for l in range(len(list_dfs)):\n",
    "# #     display(list_dfs[l].columns)\n",
    "#     for i in list_dfs[l].columns:\n",
    "#         if i not in unique_col:\n",
    "#             unique_col.append(i)\n",
    "            \n",
    "# ## Sorting to review\n",
    "# unique_col.sort()\n",
    "# unique_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:29:04.586941Z",
     "start_time": "2021-06-24T21:29:04.574941Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Removing 'Unnamed = 0' \n",
    "# unique_col = unique_col[1:-1]\n",
    "# unique_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T21:29:07.696575Z",
     "start_time": "2021-06-24T21:29:07.679579Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Creating empty dataframe to fill\n",
    "\n",
    "# df_combined = pd.DataFrame(columns=unique_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing DataFrames from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.528290Z",
     "start_time": "2021-06-24T19:17:25.500258Z"
    }
   },
   "outputs": [],
   "source": [
    "## Selecting for genre details\n",
    "title_basics = clean_file_names['imdb_title_basics']\n",
    "title_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.559289Z",
     "start_time": "2021-06-24T19:17:25.530257Z"
    }
   },
   "outputs": [],
   "source": [
    "## Selecting for budget and gross details\n",
    "movie_basics = clean_file_names['tn_movie_budgets']\n",
    "movie_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.590257Z",
     "start_time": "2021-06-24T19:17:25.561288Z"
    }
   },
   "outputs": [],
   "source": [
    "## Selecting for gross details\n",
    "movie_gross = clean_file_names['bom_movie_gross']\n",
    "movie_gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:47:31.892074Z",
     "start_time": "2021-06-24T19:47:31.861072Z"
    }
   },
   "outputs": [],
   "source": [
    "## Selecting all titles for movies based on ID\n",
    "\n",
    "title_akas = clean_file_names['imdb_title_akas']\n",
    "title_akas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T20:10:31.916319Z",
     "start_time": "2021-06-24T20:10:31.889321Z"
    }
   },
   "outputs": [],
   "source": [
    "## Selecting for tmdb_movies\n",
    "\n",
    "tmdb_movies= clean_file_names['tmdb_movies']\n",
    "tmdb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this dataframe has a weird column that duplicated the index. I will drop that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T20:11:59.620301Z",
     "start_time": "2021-06-24T20:11:59.600312Z"
    }
   },
   "outputs": [],
   "source": [
    "display(tmdb_movies.columns)\n",
    "display(tmdb_movies.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T20:13:56.954596Z",
     "start_time": "2021-06-24T20:13:56.943616Z"
    }
   },
   "outputs": [],
   "source": [
    "## Dropping column\n",
    "\n",
    "try:\n",
    "    tmdb_movies.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "## Testing results\n",
    "'Unnamed: 0' not in tmdb_movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T20:14:00.378544Z",
     "start_time": "2021-06-24T20:14:00.349563Z"
    }
   },
   "outputs": [],
   "source": [
    "tmdb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.699287Z",
     "start_time": "2021-06-24T19:17:25.593260Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Merging title_basics and movie_basics on primary title\n",
    "\n",
    "merged_basics_primary = pd.merge(title_basics,movie_basics, \n",
    "                                 left_on= 'primary_title', right_on= 'movie')\n",
    "merged_basics_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.730260Z",
     "start_time": "2021-06-24T19:17:25.716268Z"
    }
   },
   "outputs": [],
   "source": [
    "df = merged_basics_primary.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Redundant \"Movie\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.760287Z",
     "start_time": "2021-06-24T19:17:25.747258Z"
    }
   },
   "outputs": [],
   "source": [
    "## Verifying all titles/movies match - np.where faster than logical slicing\n",
    "\n",
    "for x in np.where((df.loc[:,'primary_title'] != df.loc[:,'movie']),1,0):\n",
    "    if x == 1:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.776288Z",
     "start_time": "2021-06-24T19:17:25.762255Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Dropping redundant \"movie\" column -  incl t/e to be able to rerun notebook\n",
    "\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df.drop('movie', axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "## Confirming removal\n",
    "'movie' in df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Currencies from Str to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.807255Z",
     "start_time": "2021-06-24T19:17:25.778255Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Converting gross amounts from strings to integers and removing \n",
    "\n",
    "dollar_to_int = ['production_budget','worldwide_gross','domestic_gross']\n",
    "\n",
    "for i in dollar_to_int:\n",
    "    try:\n",
    "        df[i] = df[i].map((lambda x: int(x.replace('$','').replace(',',''))))\n",
    "\n",
    "    except Exception:\n",
    "        print('---'*25)\n",
    "        print('Already converted.')\n",
    "        print()\n",
    "        \n",
    "    display(df[i][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:22:20.753658Z",
     "start_time": "2021-06-24T19:22:20.743661Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identifying Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.823289Z",
     "start_time": "2021-06-24T19:17:25.809259Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Identify the total number of missing values for the dataframe\n",
    "\n",
    "display(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:25.838289Z",
     "start_time": "2021-06-24T19:17:25.825263Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Creating function to diagnose data for null values and generate report\n",
    "def check_null(df):\n",
    "    '''Checks a given dataframe for null values in each column.\n",
    "    \n",
    "    If no null values, it prints out a confirmation of no null values.\n",
    "    \n",
    "    If null values are found, it generates a report a report indicating:\n",
    "        * Column name\n",
    "        * Datatype\n",
    "        * If object: prints most frequent value and count\n",
    "        * If int/float: prints mean, median of values for the column with null\n",
    "        values'''\n",
    "    \n",
    "    col_nan = [pair[0] for pair in zip(df.columns, df.isna().sum()) if pair[1] != 0]\n",
    "   \n",
    "    if len(col_nan) >= 1:\n",
    "        print()\n",
    "        print('The columns with missing values is/are:')\n",
    "        print()\n",
    "        print('------')\n",
    "    \n",
    "    else:\n",
    "        print('There are no null values.')\n",
    "\n",
    "    for i in col_nan:\n",
    "\n",
    "        print()\n",
    "        print(f\"** '{i}' **\")\n",
    "        print()\n",
    "        print(f'Dataype: {df[i].dtype}')\n",
    "        print()\n",
    "\n",
    "        if df[i].dtype  == 'object':\n",
    "            print(f'Mode: {df[i].value_counts().index[1]} ({df[i].value_counts()[1]}x)')\n",
    "\n",
    "        elif [(df[i].dtype  == 'int64') or df[i].dtype  == 'float64']:\n",
    "            print(f'Mean: {df[i].mean():.2f}')\n",
    "            print(f'Median: {df[i].median():.2f}')\n",
    "\n",
    "        else:\n",
    "            print(f'The \"\"{df[i].dtype}\" datatype is not supported by this function.)\n",
    "        \n",
    "        print()\n",
    "        print('------'*5)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:17:37.779217Z",
     "start_time": "2021-06-24T19:17:37.757214Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Running function and confirming functionality\n",
    "\n",
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Deprecated*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:08:01.739273Z",
     "start_time": "2021-06-24T19:08:01.731273Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Deprecated\n",
    "\n",
    "# def check_null_old(df):\n",
    "#     col_nan = []\n",
    "#     for pair in zip(df.columns, df.isna().sum()):\n",
    "#         if pair[1] == 0:\n",
    "#             pass\n",
    "#         else:\n",
    "#             col_nan.append(pair[0])\n",
    "\n",
    "#     if len(col_nan) >= 1:\n",
    "#         print()\n",
    "#         print('The columns with missing values is/are:')\n",
    "#         print()\n",
    "#         print('------')\n",
    "\n",
    "#     for i in col_nan:\n",
    "\n",
    "#         print()\n",
    "#         print(f\"** '{i}' **\")\n",
    "#         print()\n",
    "#         print(f'Dataype: {df[i].dtype}')\n",
    "#         print()\n",
    "\n",
    "#         if df[i].dtype  == 'object':\n",
    "#             print(f'Mode: {df[i].value_counts().index[1]} ({df[i].value_counts()[1]}x)')\n",
    "#             print()\n",
    "#             print('------'*5)\n",
    "\n",
    "#         elif [(df[i].dtype  == 'int64') or df[i].dtype  == 'float64']:\n",
    "#             print(f'Mean: {df[i].mean():.2f}')\n",
    "#             print(f'Median: {df[i].median():.2f}')\n",
    "#             print()\n",
    "#             print('------'*5)\n",
    "\n",
    "#         else:\n",
    "#             print('------'*5)\n",
    "            \n",
    "            \n",
    "#     return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Missing `runtime_minutes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:23:16.546592Z",
     "start_time": "2021-06-24T19:23:16.536579Z"
    }
   },
   "outputs": [],
   "source": [
    "## Calculating mean & median values to determine fill value for missing values\n",
    "\n",
    "mean_runtime = df[\"runtime_minutes\"].mean()\n",
    "\n",
    "median_runtime = df[\"runtime_minutes\"].median()\n",
    "\n",
    "abs_diff = abs(mean_runtime-median_runtime)\n",
    "\n",
    "print(f'The average and median runtimes are: {mean_runtime:,.2f} and {median_runtime:,.2f}')\n",
    "print()\n",
    "print(f'The difference between the average and median values is: {abs_diff:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Based on the minimal difference in values, either value would be a valid representation of the overall data.\n",
    ">\n",
    ">I will select the average value to fill for missing values as we don't have significant outliers. Outliers would increase the difference between the values and affect our later inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:24:44.455243Z",
     "start_time": "2021-06-24T19:24:44.438215Z"
    }
   },
   "outputs": [],
   "source": [
    "## Filling missing value with the pre-calcuated average\n",
    "\n",
    "df_filled['runtime_minutes'].fillna(mean_runtime, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:39:31.070270Z",
     "start_time": "2021-06-24T19:39:31.057237Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming the value was filled.\n",
    "\n",
    "df_filled['original_title'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:39:43.293191Z",
     "start_time": "2021-06-24T19:39:43.277189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Checking remaining columns with null values\n",
    "\n",
    "check_null(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling `original_title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:26:09.457227Z",
     "start_time": "2021-06-24T19:26:09.444226Z"
    }
   },
   "outputs": [],
   "source": [
    "## Identifying missing value\n",
    "\n",
    "df_filled[df_filled['original_title'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like this feature is only missing one value. I will try to use the \"titles_aka\" dataframe from the original datasets to check if there was a different name. Otherwise, I will use the primary title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the 'title_akas\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:59:55.686032Z",
     "start_time": "2021-06-24T19:59:55.679033Z"
    }
   },
   "outputs": [],
   "source": [
    "## Identifying ID of missing movie\n",
    "\n",
    "id_missing_title = df_filled.iloc[447][0]\n",
    "id_missing_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T20:07:12.203556Z",
     "start_time": "2021-06-24T20:07:12.179562Z"
    }
   },
   "outputs": [],
   "source": [
    "## Checking to see if the movie is in the table.\n",
    "\n",
    "id_missing_title in title_akas['title_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like the ID is not in the \"title_akas\" dataframe. I will use the primary title instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Primary title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:30:50.143303Z",
     "start_time": "2021-06-24T19:30:50.124333Z"
    }
   },
   "outputs": [],
   "source": [
    "## Slicing out the titles for replacement\n",
    "\n",
    "df_filled.iloc[447][1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:31:08.318198Z",
     "start_time": "2021-06-24T19:31:08.303196Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating variable for fillna()\n",
    "\n",
    "fill_title = df_filled.iloc[447][1]\n",
    "fill_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:32:00.977401Z",
     "start_time": "2021-06-24T19:32:00.972406Z"
    }
   },
   "outputs": [],
   "source": [
    "## Filling missing value with title\n",
    "\n",
    "df_filled['original_title'].fillna('fill_title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:32:08.843441Z",
     "start_time": "2021-06-24T19:32:08.830441Z"
    }
   },
   "outputs": [],
   "source": [
    "## Confirming the value was filled\n",
    "\n",
    "df_filled['original_title'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I identified the single missing null value for the \"original_title\" column.\n",
    ">\n",
    "> I decided to fill the value with the \"primary_title\" value as many other columns in the dataframe shared primary/original titles as well.\n",
    ">\n",
    "> I used .iloc indexing to slice out the value and then filled the missing value via the .fillna() method\n",
    ">\n",
    "> The final result is a filled column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:33:54.962396Z",
     "start_time": "2021-06-24T19:33:54.940359Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Checking remaining columns with null values\n",
    "\n",
    "check_null(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling `genres`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T19:40:39.838394Z",
     "start_time": "2021-06-24T19:40:39.806405Z"
    }
   },
   "outputs": [],
   "source": [
    "## Identifying missing value\n",
    "\n",
    "df_filled[df_filled['genres'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This series of missing values is much more difficult to fill versus the other three as I don't have any other rows to reference, and the datatype for the value would be a string, so I can't use mean/median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Seasons and Quarters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.129535Z",
     "start_time": "2021-06-23T23:12:40.960537Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Changing release date to datetime datatype\n",
    "\n",
    "df_filled['release_datetime'] = pd.to_datetime(df_filled['release_date'])\n",
    "df_filled['release_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.144536Z",
     "start_time": "2021-06-23T23:12:41.133540Z"
    }
   },
   "outputs": [],
   "source": [
    "## Using datetime dtype to create months column\n",
    "df_filled['release_dt_month'] = df_filled['release_datetime'].dt.month_name()\n",
    "df_filled['release_dt_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.160541Z",
     "start_time": "2021-06-23T23:12:41.148544Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled['release_quarter'] = df_filled['release_datetime'].dt.quarter\n",
    "df_filled['release_quarter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.176536Z",
     "start_time": "2021-06-23T23:12:41.166540Z"
    }
   },
   "outputs": [],
   "source": [
    "## Inspecting original values\n",
    "df_filled['release_date'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.192536Z",
     "start_time": "2021-06-23T23:12:41.179541Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Pulling month\n",
    "test_month = df_filled['release_date'][0][:3]\n",
    "test_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.208536Z",
     "start_time": "2021-06-23T23:12:41.195537Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating new column for the month of each release date\n",
    "release_month = []\n",
    "\n",
    "for movie in df_filled['release_date']:\n",
    "    release_month.append(movie[:3])\n",
    "    \n",
    "df_filled['release_month_manual'] = release_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.240537Z",
     "start_time": "2021-06-23T23:12:41.213538Z"
    }
   },
   "outputs": [],
   "source": [
    "## Using map and lambda functions to slice out month from string\n",
    "df_filled['release_month_manual'] = df_filled['release_date'].map(lambda x: x[:3])\n",
    "df_filled['release_month_manual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.271535Z",
     "start_time": "2021-06-23T23:12:41.243542Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating seasons based on meteorological definitions of each season\n",
    "season = []\n",
    "\n",
    "for month in df_filled['release_month_manual']:\n",
    "    if month == 'Jan':\n",
    "        season.append('Winter')\n",
    "    elif month == 'Feb':\n",
    "        season.append('Winter')\n",
    "    elif month == 'Mar':\n",
    "        season.append('Spring')\n",
    "    elif month == 'Apr':\n",
    "        season.append('Spring')\n",
    "    elif month == 'May':\n",
    "        season.append('Spring')\n",
    "    elif month == 'Jun':\n",
    "        season.append('Summer')\n",
    "    elif month == 'Jul':\n",
    "        season.append('Summer')\n",
    "    elif month == 'Aug':\n",
    "        season.append('Summer')\n",
    "    elif month == 'Sep':\n",
    "        season.append('Fall')\n",
    "    elif month == 'Oct':\n",
    "        season.append('Fall')\n",
    "    elif month == 'Nov':\n",
    "        season.append('Fall')\n",
    "    elif month == 'Dec':\n",
    "        season.append('Winter')\n",
    "    else:\n",
    "        print('na')\n",
    "\n",
    "df_filled['release_season_manual'] = season\n",
    "df_filled['release_season_manual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.316536Z",
     "start_time": "2021-06-23T23:12:41.275537Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Profit and ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.332536Z",
     "start_time": "2021-06-23T23:12:41.318537Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled['profit'] = df_filled['worldwide_gross'] - df_filled['production_budget']\n",
    "df_filled['profit'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.348536Z",
     "start_time": "2021-06-23T23:12:41.338540Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled['ROI'] = (df_filled['worldwide_gross'] - df_filled['production_budget'])/df_filled['production_budget']\n",
    "df_filled['ROI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: What genres perform the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Genres into Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:41.363536Z",
     "start_time": "2021-06-23T23:12:41.350537Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Via map & lambda - slower than .str\n",
    "# df_filled['genres_list'] = df_filled['genres'].map(lambda x: x.split(','))\n",
    "# df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:43.407616Z",
     "start_time": "2021-06-23T23:12:43.391615Z"
    }
   },
   "outputs": [],
   "source": [
    "## Via .str and string methods (faster than map/lambda)\n",
    "df_filled['genres_str'] = df_filled['genres'].str.title().str.split(',')\n",
    "df_filled['genres_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:43.502640Z",
     "start_time": "2021-06-23T23:12:43.410616Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating separate df for plotting with each genre on a separate row\n",
    "plot_df = df_filled.explode('genres_str')\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Worldwide Gross per Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:43.517612Z",
     "start_time": "2021-06-23T23:12:43.505644Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Defining a function to perform aggregation and plot the data\n",
    "\n",
    "def sort_genres_sum(df, col_to_sort, agg='sum', verbose=True):\n",
    "    '''Creates a new dataframe from a given dataframe created by the sum of\n",
    "    all values for each genre, then sorted by the specified column name.\n",
    "    \n",
    "    Args & kwargs:\n",
    "    df - original dataframe to be sorted\n",
    "    col_to_sort - column name (str) by which to sort the data\n",
    "    '''\n",
    "    ## Adding functionality to handle different aggregation methods\n",
    "    if agg == 'sum':\n",
    "        agg_func = np.sum\n",
    "        agg_title = 'Total'\n",
    "    elif agg == 'median':\n",
    "        agg_func = np.median\n",
    "        agg_title = 'Median'\n",
    "    else:\n",
    "        agg_func = np.mean\n",
    "        agg_title = 'Average'\n",
    "    \n",
    "    ## Determining performance rankings and creating a list of names for viz\n",
    "    idx = list(df.groupby(\"genres_str\", as_index=True).agg(agg_func).sort_values(by = col_to_sort, ascending=False).index)\n",
    "    \n",
    "    ## Graphing results of agg function ordered by index (above)\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    sns.barplot(data=df, x= 'genres_str', y= col_to_sort, order = idx, estimator = agg_func)\n",
    "    plt.xticks(rotation=45, ha= 'right')\n",
    "    plt.suptitle(f'Total {col_to_sort.title().replace(\"_\", \" \")} by Genre')\n",
    "    plt.xlabel('Genres')\n",
    "    plt.ylabel(f'Total {col_to_sort.title().replace(\"_\", \" \")}');\n",
    "    \n",
    "    ## Adding option to turn off dataframe showing results\n",
    "    if verbose == True:\n",
    "        display(df.sort_values(col_to_sort, ascending=False))\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:43.533615Z",
     "start_time": "2021-06-23T23:12:43.522618Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_filled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:43.549618Z",
     "start_time": "2021-06-23T23:12:43.536614Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_filled.sort_values('domestic_gross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:44.841617Z",
     "start_time": "2021-06-23T23:12:43.552622Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Testing Function\n",
    "\n",
    "sort_genres_sum(plot_df, col_to_sort='worldwide_gross', agg='sum');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">* **Top three genres:** Adventure, Action, Drama\n",
    ">* **Lowest three genres:** Western, News, Reality-TV\n",
    ">* On this graph, musicals are ranked much lower due to their smaller total gross box office sales (versus calculating the average of all gross values).\n",
    "\n",
    "**Suggestions**\n",
    ">* **Safest Genres (by Gross)** are the top three genres\n",
    "    * Lowest points on the error bars indicate high performance even at their worst.\n",
    ">* **Select from:** Action, Animation, Adventure, Fantasy, Sci-Fi, Family, or Musicals\n",
    "    * All others show poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Gross per Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:44.857612Z",
     "start_time": "2021-06-23T23:12:44.845615Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Defining a function to perform aggregation and plot the data\n",
    "\n",
    "def sort_genres_avg(df, col_to_sort):\n",
    "    '''Creates a new dataframe from a given dataframe created by the average of\n",
    "    all values for each genre, then sorted by the specified column name.\n",
    "    \n",
    "    Args & kwargs:\n",
    "    df - original dataframe to be sorted\n",
    "    col_to_sort - column name (str) by which to sort the data\"'''\n",
    "    \n",
    "    df1 = df.groupby(\"genres_str\").mean().reset_index().sort_values(by = col_to_sort, ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(15,4))\n",
    "    sns.barplot(data=df1, x= 'genres_str', y= col_to_sort )\n",
    "    plt.xticks(rotation=45, ha= 'right')\n",
    "    plt.suptitle('Average Worldwide Gross by Genre')\n",
    "    plt.xlabel('Genres')\n",
    "    plt.ylabel('Total Worldwide Gross ($)');\n",
    "    \n",
    "    return df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:45.385612Z",
     "start_time": "2021-06-23T23:12:44.861617Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sort_genres_avg(plot_df, col_to_sort='worldwide_gross')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Code - Saving just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:45.400613Z",
     "start_time": "2021-06-23T23:12:45.388613Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ## Visualizing sorted sum \n",
    "\n",
    "# df_sorted = sort_genres_sum(plot_df, 'worldwide_gross')\n",
    "\n",
    "# plt.figure(figsize=(15,4))\n",
    "# sns.barplot(data=df_sorted, x= 'genres_str', y='worldwide_gross')\n",
    "# plt.xticks(rotation=45, ha= 'right')\n",
    "# plt.suptitle('Total Worldwide Gross by Genre')\n",
    "# plt.xlabel('Genres')\n",
    "# plt.ylabel('Total Worldwide Gross ($)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:45.416613Z",
     "start_time": "2021-06-23T23:12:45.404621Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ## Visualizing sorted average \n",
    "\n",
    "# avg_sorted = sort_genres_avg(plot_df, 'worldwide_gross')\n",
    "\n",
    "# plt.figure(figsize=(15,4))\n",
    "# sns.barplot(data=avg_sorted, x= 'genres_str', y='worldwide_gross')\n",
    "# plt.xticks(rotation=45, ha= 'right')\n",
    "# plt.suptitle('Total Worldwide Gross by Genre')\n",
    "# plt.xlabel('Genres')\n",
    "# plt.ylabel('Total Worldwide Gross ($)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:45.431612Z",
     "start_time": "2021-06-23T23:12:45.418619Z"
    }
   },
   "outputs": [],
   "source": [
    "# def sort_genres_avg(df, col_to_sort):\n",
    "#     '''Creates a new dataframe from a given dataframe created by the average of\n",
    "#     all values for each genre, then sorted by the specified column name.\n",
    "    \n",
    "#     Args & kwargs:\n",
    "#     df - original dataframe to be sorted\n",
    "#     col_to_sort - column name (str) by which to sort the data\"'''\n",
    "    \n",
    "#     df1 = df.groupby(\"genres_str\").agg('mean').reset_index().sort_values(by = col_to_sort, ascending=False)\n",
    "    \n",
    "#     return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:45.446613Z",
     "start_time": "2021-06-23T23:12:45.433615Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ## First version of visualizing results - \n",
    "\n",
    "# plt.figure(figsize=(15,4))\n",
    "# sns.barplot(data=plot_df, x= 'genres_str', y='worldwide_gross')#, order=sum_gross_ww)\n",
    "# plt.xticks(rotation=45, ha= 'right')\n",
    "# plt.suptitle('Worldwide Gross by Genre')\n",
    "# plt.xlabel('Genres')\n",
    "# plt.ylabel('Worldwide Gross ($)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:45.462614Z",
     "start_time": "2021-06-23T23:12:45.449613Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ## Not working - attempted to create function to sort and visualize\n",
    "# def visualize_metrics(df, col_to_sort, sort_order):\n",
    "    \n",
    "#     df_sorted = df.groupby(\"genres_str\").sum().reset_index().sort_values(by = col_to_sort, ascending=False)\n",
    "    \n",
    "#     plt.figure(figsize=(15,4))\n",
    "#     sns.barplot(data=df_sorted, x= 'genres_str', y=col_to_sort, order=sort_order)\n",
    "#     plt.xticks(rotation=45, ha= 'right')\n",
    "#     plt.suptitle('Worldwide Gross by Genre')\n",
    "#     plt.xlabel('Genres')\n",
    "#     plt.ylabel(col_to_sort);\n",
    "    \n",
    "#     return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI per Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:45.477611Z",
     "start_time": "2021-06-23T23:12:45.465614Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating list of genres based on average ROI for graphing purposes\n",
    "\n",
    "mean_roi = list(plot_df.groupby(\"genres_str\").mean()['ROI'].sort_values(ascending=False).index)\n",
    "# mean_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:46.757613Z",
     "start_time": "2021-06-23T23:12:45.479614Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Visualizing Average Worldwide Gross per Genre\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "sns.barplot(data=plot_df, x= 'genres_str', y='ROI', order=mean_roi)\n",
    "plt.xticks(rotation=45, ha= 'right')\n",
    "plt.suptitle('Average Return-on-Investment by Genre')\n",
    "plt.xlabel('Genres')\n",
    "plt.ylabel('ROI (%)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">* **Top three genres:** Animation, Adventure, and Sci-Fi\n",
    ">* **Lowest three genres:** Reality-TV, War and News\n",
    ">* *Musicals are a high-risk, high-reward option*\n",
    "    * Their gross can exceed Animation, or fall below the top 5 genres.\n",
    "\n",
    "**Suggestions**\n",
    ">* **Safest Genres (by Gross)** are the top three genres\n",
    "    * Lowest points on the error bars indicate high gross performance even at their worst\n",
    ">* Select from Action, Animation, Adventure, Fantasy, Sci-Fi, Family, or Musicals\n",
    "    * All others show poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A1: Top Genres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* List mean, roi for evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Seasonal Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Performance - All Movies (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:47.167615Z",
     "start_time": "2021-06-23T23:12:46.760613Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Creating basic overview\n",
    "g = sns.barplot(data=plot_df, x='release_season_manual', y='ROI', \n",
    "                order=['Spring', 'Summer', 'Fall', 'Winter'], \n",
    "                estimator=np.mean)\n",
    "g.set_xlabel('Seasons')\n",
    "g.set_ylabel('ROI(%)')\n",
    "g.set_title('Seasonal Performance (All Movies)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Performance - All Movies (Ww Gross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:47.572612Z",
     "start_time": "2021-06-23T23:12:47.170626Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Creating basic overview\n",
    "g = sns.barplot(data=plot_df, x='release_season_manual', y='worldwide_gross', \n",
    "                order=['Spring', 'Summer', 'Fall', 'Winter'], \n",
    "                estimator=np.mean)\n",
    "g.set_xlabel('Seasons')\n",
    "g.set_ylabel('Worldwide Gross')\n",
    "g.set_title('Seasonal Performance (All Movies)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">* Summer is the best season for releases, with winter being the worst time.\n",
    ">* Summer and Spring seasons seem to be the most productive seasons.\n",
    ">* Fall and Winter perform worse.\n",
    "\n",
    "**Suggestions**\n",
    ">* Focus release times in Summer/Spring\n",
    ">* Avoid Fall/Winter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre Performance by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:52.411615Z",
     "start_time": "2021-06-23T23:12:47.576615Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Visualizing each genre's performance by season\n",
    "g = sns.catplot(data=plot_df, col='release_season_manual',\n",
    "            y='ROI', kind='bar', x='genres_str', col_wrap=2, \n",
    "            aspect=1.75, order=mean_roi)\n",
    "(g.set_axis_labels('Category', 'ROI (%)')\n",
    " .set_xticklabels(rotation=45)\n",
    " .set_titles(\"{col_name}\"))\n",
    " \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:57.248612Z",
     "start_time": "2021-06-23T23:12:52.413630Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Visualizing each genre's performance by season\n",
    "g = sns.catplot(data=plot_df, col='release_season_manual',\n",
    "            y='worldwide_gross', kind='bar', x='genres_str', col_wrap=2, \n",
    "            aspect=1.75)#, sharex=False)\n",
    "(g.set_axis_labels('Category', 'Worldwide Gross ($)')\n",
    " .set_xticklabels(rotation=45)\n",
    " .set_titles(\"{col_name}\"))\n",
    " \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">* Springtime releases show highest gross performance on average\n",
    ">* Wintertime shows lowest performances across all genres\n",
    ">* The results match up with our overall view for all genres\n",
    "\n",
    "**Suggestions**\n",
    ">* To maximize profitability of musicals, release in spring\n",
    ">* Avoid releasing Animations in the winter - all other seasons perform better\n",
    ">* Avoid releasing news-related movies in the Spring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Performance -  Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">\n",
    ">The top five genres tend to perform relatively well regardless of the season with little difference between each season.\n",
    ">\n",
    "> Musicals show a strongest performance in the springtime - it is only worthwhile to release a musical in the spring.\n",
    ">\n",
    "**Questions**\n",
    "> \n",
    ">What is the profitability and return on investment for each genre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarterly Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would the data look when comparing seasons to quarters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:57.264615Z",
     "start_time": "2021-06-23T23:12:57.253615Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Sorting by release quarters for graphing\n",
    "df_filled.sort_values('release_quarter', inplace=True)\n",
    "df_filled.reset_index(drop=True, inplace=True)\n",
    "# df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:12:57.700622Z",
     "start_time": "2021-06-23T23:12:57.267613Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Creating basic overview\n",
    "g = sns.barplot(data=plot_df, x='release_quarter', y='worldwide_gross')\n",
    "g.set_xlabel('Quarters')\n",
    "g.set_ylabel('Worldwide Gross')\n",
    "g.set_title('Quarterly Performance (All Movies)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">* \n",
    ">* \n",
    ">* \n",
    "\n",
    "**Suggestions**\n",
    ">* \n",
    ">* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:13:02.962612Z",
     "start_time": "2021-06-23T23:12:57.703628Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Generating figure for quarterly performance breakdown\n",
    "g = sns.catplot(data=plot_df, col='release_quarter',\n",
    "            y='worldwide_gross', kind='bar', x='genres_str', col_wrap=2, \n",
    "            aspect=1.75)#, sharex=False)\n",
    "(g.set_axis_labels('Category', 'Worldwide Gross ($)')\n",
    " .set_xticklabels(rotation=45)\n",
    " .set_titles(\"Quarter {col_name}\"))\n",
    " \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">* \n",
    ">* \n",
    ">* \n",
    "\n",
    "**Suggestions**\n",
    ">* \n",
    ">* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:13:02.978612Z",
     "start_time": "2021-06-23T23:13:02.969615Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# g = sns.catplot(x = 'genres_list', y='worldwide_gross', \n",
    "#                hue = 'release_quarter',data=plot_df, kind='bar', aspect=3.65)\n",
    "# g.set_xticklabels(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:13:02.994612Z",
     "start_time": "2021-06-23T23:13:02.983619Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# g = sns.catplot(x = 'genres_list', y='worldwide_gross',\n",
    "#                 hue = 'release_season_manual',data=plot_df, kind='bar',\n",
    "#                 aspect=3.65)\n",
    "# g.set_xticklabels(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing S & Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:13:03.820613Z",
     "start_time": "2021-06-23T23:13:02.997616Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Comparing Seasonal/Quarterly breakdowns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(7,7))\n",
    "sns.barplot(x = 'release_season_manual', y='worldwide_gross',data=plot_df, \n",
    "            ax=axes[0], order=['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "sns.barplot(x = 'release_quarter', y='worldwide_gross', data=plot_df,\n",
    "            ax=axes[1])\n",
    "\n",
    "## Changing settings\n",
    "axes[0].set_xlabel(\"Seasons\")\n",
    "axes[0].set_ylabel('Worldwide Gross')\n",
    "\n",
    "axes[1].set_xlabel(\"Quarters\")\n",
    "axes[1].set_ylabel('Worldwide Gross')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:13:12.917613Z",
     "start_time": "2021-06-23T23:13:03.822612Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Creating single visualization to compare seasonal and quarterly performances\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(17,10))\n",
    "sns.barplot(x = 'genres_str', y='worldwide_gross',\n",
    "            hue = 'release_season_manual',data=plot_df, ax=axes[0])\n",
    "sns.barplot(x = 'genres_str', y='worldwide_gross', hue = 'release_quarter',\n",
    "            data=plot_df, ax=axes[1])\n",
    "\n",
    "## Changing settings\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(),rotation=45, ha='right')\n",
    "axes[0].set_xlabel(\"Genres\")\n",
    "axes[0].set_ylabel('Worldwide Gross')\n",
    "axes[0].legend(title='Seasons')\n",
    "\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(),rotation=45, ha='right')\n",
    "axes[1].set_xlabel(\"Genres\")\n",
    "axes[1].set_ylabel('Worldwide Gross')\n",
    "axes[1].legend(title='Quarters')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">* \n",
    ">* \n",
    ">* \n",
    "\n",
    "**Suggestions**\n",
    ">* \n",
    ">* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHE: Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:13:34.596849Z",
     "start_time": "2021-06-23T23:13:34.578843Z"
    }
   },
   "outputs": [],
   "source": [
    "## Getting unique values for genres\n",
    "\n",
    "unique_genres = plot_df['genres_str'].unique()\n",
    "unique_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:13:13.501616Z",
     "start_time": "2021-06-23T23:12:43.530Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_filled['family'] = (df_filled['genres_str'] == 'Family').astype(int)\n",
    "# df_filled#['family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:14:44.237352Z",
     "start_time": "2021-06-23T23:14:44.215352Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled['genres'].str.contains('Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:15:08.778268Z",
     "start_time": "2021-06-23T23:15:08.692248Z"
    }
   },
   "outputs": [],
   "source": [
    "## Manually creating OHE columns for each genre\n",
    "\n",
    "for genre in unique_genres:\n",
    "    df_filled[genre] = (df_filled['genres'].str.contains(genre)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:16:26.187855Z",
     "start_time": "2021-06-23T23:16:26.175857Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:17:26.921554Z",
     "start_time": "2021-06-23T23:17:26.917565Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_filled.drop(columns=['genres', 'genres_str'], inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:17:47.486037Z",
     "start_time": "2021-06-23T23:17:47.436065Z"
    }
   },
   "outputs": [],
   "source": [
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations/Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:17:48.233082Z",
     "start_time": "2021-06-23T23:17:48.215077Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ## Code copied from P2proj\n",
    "\n",
    "## Determining each feature's relationship with price\n",
    "\n",
    "## 1. Drop categorical columns\n",
    "## 2. Create correlation with target variable \n",
    "## 3. Display top/bottom 5 values\n",
    "\n",
    "# df_corr = df.drop(['price', 'id', 'lat','long'], axis=1).corrwith(df['price']).sort_values(ascending=False)\n",
    "# display(df_corr[0:5],df_corr[-6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:17:48.638100Z",
     "start_time": "2021-06-23T23:17:48.634077Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ## Attempted to create a loop to check the datetype and add to a list for columns\n",
    "\n",
    "\n",
    "# # for each runtime in the column, check if it is not a string\n",
    "# #  if it is not, then zip that value with the value in the \"primary_title\" column\n",
    "# #  then, add the zipped value to a list\n",
    "# # finally, print the final list\n",
    "\n",
    "# cat_col_list = []\n",
    "\n",
    "# for i in col_list:\n",
    "#     for n in range(len(col_list)):\n",
    "#         if type(i[n]) == float:\n",
    "# #             cat_col_list.append(i)\n",
    "#             print(i)\n",
    "        \n",
    "# # cat_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:17:49.042078Z",
     "start_time": "2021-06-23T23:17:49.040078Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Realized I can't treat the 'runtime' column as either cat/col due to mixed dt w/in col\n",
    "\n",
    "# display(list(df_filled.columns))\n",
    "\n",
    "# display(list(df_filled.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:17:49.501076Z",
     "start_time": "2021-06-23T23:17:49.481077Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Identifying datatypes for each title to split into cat/cont/drop lists\n",
    "cat_col = list(zip(list(df_filled.columns),list(df_filled.dtypes)))\n",
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:18:09.867159Z",
     "start_time": "2021-06-23T23:18:09.861174Z"
    }
   },
   "outputs": [],
   "source": [
    "## Breaking out each feature into either categorical/continuous/\"to be dropped\"\n",
    "\n",
    "targets = ['profit','ROI']\n",
    "\n",
    "cont_feat = ['start_year','production_budget']\n",
    "\n",
    "cat_feat = ['release_dt_month','release_quarter','release_season_manual']\n",
    "\n",
    "drop_feat = ['id','tconst','primary_title','original_title','release_datetime',\n",
    "        'runtime_minutes','release_date','release_month_manual','domestic_gross','worldwide_gross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:18:10.477153Z",
     "start_time": "2021-06-23T23:18:10.426154Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating a new dataframe for correlation matrix\n",
    "\n",
    "df_for_corr = df_filled.drop(columns = drop_feat).copy().reset_index(drop=True)\n",
    "df_for_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:18:16.154971Z",
     "start_time": "2021-06-23T23:18:16.134966Z"
    }
   },
   "outputs": [],
   "source": [
    "df_corr = df_for_corr.corrwith(df_for_corr['profit']).sort_values(ascending=False)\n",
    "df_corr\n",
    "# display(df_corr[0:5],df_corr[-6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:18:18.338059Z",
     "start_time": "2021-06-23T23:18:18.328065Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating function to provide correlation matrix to determine multicollinearity\n",
    "\n",
    "def calc_df_corr(df, list_cats, target_col):\n",
    "    '''Identifying correlations within the data'''\n",
    "    \n",
    "    df_corr = df.drop(list_cats, axis=1).corrwith(df[target_col]).sort_values(ascending=False)\n",
    "    \n",
    "#     display(df_corr[0:5],df_corr[-6:-1])\n",
    "    \n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:18:19.276268Z",
     "start_time": "2021-06-23T23:18:19.255280Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_df_corr(df=df_for_corr, list_cats=cat_feat, target_col = 'profit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:24:20.495556Z",
     "start_time": "2021-06-23T23:24:20.457523Z"
    }
   },
   "outputs": [],
   "source": [
    "## Save the features that we used previously - I will use these features \n",
    "## to fit my model.\n",
    "\n",
    "X = df_filled[[*unique_genres,*cont_feat,*cat_feat]].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:42.716958Z",
     "start_time": "2021-06-23T23:34:42.707958Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating the y values by setting them equal to the 'price' values from the dataframe\n",
    "\n",
    "y = df_filled['profit'].copy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:42.968957Z",
     "start_time": "2021-06-23T23:34:42.952959Z"
    }
   },
   "outputs": [],
   "source": [
    "## Verifying the two groups are of equal length\n",
    "\n",
    "print(X.shape[0] == y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:43.172988Z",
     "start_time": "2021-06-23T23:34:43.156959Z"
    }
   },
   "outputs": [],
   "source": [
    "## Establishing the train and test data before doing anything else\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:43.345959Z",
     "start_time": "2021-06-23T23:34:43.319960Z"
    }
   },
   "outputs": [],
   "source": [
    "## Using OneHotEncoder to create columns for the categorical variables.\n",
    "\n",
    "## Create the OHE without \"drop='first\" as it would throw an error in this case\n",
    "ohe = OneHotEncoder(drop = 'first', sparse=False)\n",
    "\n",
    "## Using OHE on our categorical variables for training (NOT testing)\n",
    "train_ohe = ohe.fit_transform(X_train[cat_feat])\n",
    "test_ohe = ohe.transform(X_test[cat_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:43.546960Z",
     "start_time": "2021-06-23T23:34:43.542960Z"
    }
   },
   "outputs": [],
   "source": [
    "## Getting feature names from our list of categories\n",
    "feat_col_name = ohe.get_feature_names(cat_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:43.763958Z",
     "start_time": "2021-06-23T23:34:43.757959Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating dataframes from the results of our fit&transform and transform\n",
    "\n",
    "train_ohe_df = pd.DataFrame(train_ohe, columns=feat_col_name, index=X_train.index)\n",
    "\n",
    "test_ohe_df = pd.DataFrame(test_ohe, columns=feat_col_name, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:43.967957Z",
     "start_time": "2021-06-23T23:34:43.934961Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reviewing one of the resulting dataframes\n",
    "test_ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:44.170958Z",
     "start_time": "2021-06-23T23:34:44.155960Z"
    }
   },
   "outputs": [],
   "source": [
    "## Concatenating the two training dataframes after OHE\n",
    "X_train_ohe = pd.concat([X_train.drop(cat_feat, axis=1), train_ohe_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:44.448968Z",
     "start_time": "2021-06-23T23:34:44.425958Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:45.135991Z",
     "start_time": "2021-06-23T23:34:45.092957Z"
    }
   },
   "outputs": [],
   "source": [
    "## Concatenating the two test dataframes after OHE\n",
    "X_test_ohe = pd.concat([X_test.drop(cat_feat, axis=1), test_ohe_df], axis=1)\n",
    "X_test_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:45.515958Z",
     "start_time": "2021-06-23T23:34:45.494956Z"
    }
   },
   "outputs": [],
   "source": [
    "## Instantiating the model and fitting it\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:45.965957Z",
     "start_time": "2021-06-23T23:34:45.933960Z"
    }
   },
   "outputs": [],
   "source": [
    "## Checking the R^2 for train and test\n",
    "\n",
    "train_r = lr.score(X_train_ohe, y_train)\n",
    "print(f'R-Square value for training data is {round(train_r,3)}.')\n",
    "\n",
    "test_r = lr.score(X_test_ohe, y_test)\n",
    "print(f'R-Square value for test data is {round(test_r,3)}.')\n",
    "\n",
    "## Getting model coefficients\n",
    "train_coef = pd.Series(lr.coef_, index=X_train_ohe.columns)\n",
    "train_coef['intercept'] = lr.intercept_\n",
    "\n",
    "## Displaying resulting features and coefficients\n",
    "train_coef.sort_values(ascending=False)#.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Statsmodels Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:35:11.112920Z",
     "start_time": "2021-06-23T23:35:11.094925Z"
    }
   },
   "outputs": [],
   "source": [
    "def diagnose_model(model, figsize=(10,5)):\n",
    "    \"\"\" ---\n",
    "    \n",
    "    Argument:\n",
    "        * model: provide the linear regression model for diagnostics\n",
    "    \n",
    "    Keyword Argument:\n",
    "        * figsize: default (10,5); can increase/decrease for larger/smaller\n",
    "    ---\n",
    "    \n",
    "    * Display the summary details of the provided model\n",
    "    * Create two scatter plots to test assumptions of linearity\n",
    "        * Predictions: verifying homoscedasticity (no cone-shapes)\n",
    "        * Residuals: confirming normal distribution of residuals\n",
    "    ---\n",
    "    \n",
    "    \"\"\"\n",
    "    display(model.summary())\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "\n",
    "    axes[0].scatter(model.predict(), model.resid)\n",
    "    axes[0].axhline()\n",
    "    axes[0].set_xlabel('Model Predictions')\n",
    "    axes[0].set_ylabel('Model Residuals')\n",
    "    axes[0].set_title('Testing for Homoscedasticity')\n",
    "\n",
    "    sms.graphics.qqplot(data=model.resid, fit=True, line = \"45\", ax=axes[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:46.477960Z",
     "start_time": "2021-06-23T23:34:46.454956Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_ohe = sms.add_constant(X_train_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:34:46.929955Z",
     "start_time": "2021-06-23T23:34:46.905957Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_ohe = sms.add_constant(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:37:09.665295Z",
     "start_time": "2021-06-23T23:37:09.128294Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = sms.OLS(y_train, X_train_ohe).fit()\n",
    "\n",
    "diagnose_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T23:38:25.112626Z",
     "start_time": "2021-06-23T23:38:24.117764Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.displot(y_train, aspect=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Outliers\n",
    "* Adding features from other df's at start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env-bmc)",
   "language": "python",
   "name": "learn-env-bmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "318.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
